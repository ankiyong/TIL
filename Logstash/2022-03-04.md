#### 코덱

코덱은 독립적으로 동작하지 않고 입출력 과정에서 사용되는 플러그인이다. 

입/출력시 메시지를 적절한 형ㅊ태로 변환하는 스트림 필터다.

###### 주요 코덱

- json 
- plain
- rubydebug

```bash
#json코덱
input {
  file {
    path => "C:/logstash-7.10.0/config/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
    codec => "json"
  }
}

output {
  stdout { }
}
```

```bash
#오류발생
"message" => "[2020/01/02 14:19:25]   [ID2] 218.25.32.70 1070 [warn] - busy server.\r",
      "@version" => "1",
    "@timestamp" => 2022-03-04T00:19:32.437Z,
          "host" => "DESKTOP-V9N5D3Q",
          "path" => "C:/logstash-7.10.0/config/filter-example.log",
          "tags" => [
        [0] "_jsonparsefailure"
    ]
}
```

입력 파일은 플레인 텍스트 형식인데 JSON형식으로 인코딩을 시도했기 때문이다. 

```bash
#plain 코텍으로 수정해서 실행
input {
  file {
    path => "C:/logstash-7.10.0/config/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
    codec => "plain"
  }
}

output {
  stdout { }
}
```

오류가 발생하지 않는다.

```bash
      "message" => "[2020-01-02 14:17] [ID1] 192.10.2.6 9500 [INFO] - connected.\r",
          "host" => "DESKTOP-V9N5D3Q",
          "path" => "C:/logstash-7.10.0/config/filter-example.log",
      "@version" => "1",
    "@timestamp" => 2022-03-04T00:22:06.596Z
}
{
       "message" => "[2020/01/02 14:19:25]   [ID2] 218.25.32.70 1070 [warn] - busy server.\r",
          "host" => "DESKTOP-V9N5D3Q",
          "path" => "C:/logstash-7.10.0/config/filter-example.log",
      "@version" => "1",
    "@timestamp" => 2022-03-04T00:22:06.627Z		
```

이번엔 출력 코덱을 적용해본다.

```bash
input {
  file {
    path => "C:/logstash-7.10.0/config/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

output {
  stdout {
    #codec => "line"
    #codec => "json"
    #codec => "rubydebug"
 }
}
```

(결과는 다시 해보면서 확인해 볼 것)



#### 다중 파이프라인 구성

pipelines.yml 파일 안에 다음 내용을 추가해준다.

ls가 실행되면서 pipelines.yml의 내용을 보고 2개의 파이프라인을 동시에 수행하게 된다. 

```bash
- pipeline.id : mypipe1
  path.config : "/logstash-7.10.0/config/mypipe1.conf"
- pipeline.id : mypipe2
  path.config : "/logstash-7.10.0/config/mypipe2.conf"
```

각각의 conf파일은 다음과 같이 설정한다. 

```bash
#mypipe1
input {
  file {
    path => "C:/elasticsearch-7.10.2/logs/elasticsearch.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

output {
  stdout {}
}
```

```bash
#mypipe2
input {
  file {
    path => "C:/elasticsearch-7.10.2/logs/gc.log"
    start_position => "beginning"
    sincedb_path => "nul"

  }
}

output {
  elasticsearch {
    index => "multipipe_pipe2"
  }
}
```



#### 모니터링

#### LS로 csv파일 다루기

ls 파이프라인의 인풋으로 csv가 들어오기 때문에 파일 플러그인을 사용한다. 

```bash
input {
  file {
    path => "C:/kaggle/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}
	output {
  stdout {}
}
```

이제 원하는 형태로 읽어들인 csv를 가공해본다. 

```bash
input {
  file {
    path => "C:/kaggle/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

#필터는 csv플러그인을 사용해서 구분자를 ,로 설정해 문자열을 구분자 기준으로 분류한다. 
#출력할 필드의 이름을 columns 옵션을 사용해서 명시해준다.
#사용하지 않을 필드는 remove_field 옵션에 명시해줘 삭제한다.
#skip_header 옵션을 사용해서 컬럼명이 있는 헤더를 삭제한다.
filter {
  csv {
    separator => ","
    columns => ["budget","genres","homepage","id","keywords","original_language",
    "original_title","overview","popularity","production_companies","production_countries",
    "_release_date","revenue","runtime","spoken_languages","status","tagline",
    "title","vote_average","vote_count"]
    remove_field => ["message", "production_companies", "production_countries",
    "keywords", "spoken_languages", "@timestamp", "path", "@version", "host"]
    skip_header => true
  }
#date 플러그인으로 시간포맷을 따르는 문자열을 ls의 날짜/시간 타입으로 인덱싱 가능하도록 변경하고 필드 이름을 변경한다. 
  date {
    match => ["_release_date", "YYYY-MM-dd"]
    target => "release_date"
    timezone => "UTC"
    remove_field => "_release_date"
  }
}

output {
  stdout {}
}
```



#### 루비 필터를 이용한 파싱





```bash
input {
  file {
    path => "C:/kaggle/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  csv {
    separator => ","
    columns => ["budget","genres","homepage","id","keywords","original_language",
    "original_title","overview","popularity","production_companies","production_countries",
    "_release_date","revenue","runtime","spoken_languages","status","tagline",
    "title","vote_average","vote_count"]
    remove_field => ["message", "production_companies", "production_countries",
    "keywords", "spoken_languages", "@timestamp", "path", "@version", "host"]
    skip_header => true
  }
  date {
    match => ["_release_date", "YYYY-MM-dd"]
    target => "release_date"
    timezone => "UTC"
    remove_field => "_release_date"
  }
  ruby {
    code => "
    genres = JSON.parse(event.get('genres')).map{ |genre| genre['name'] }
    event.set('genres', genres)
    "
  }
}

output {
  stdout {}
}
```



#### 인덱스 매핑

ls에 파싱된 데이터들이 es로 인덱싱 되기 위해서는 es의 매핑 작업이 필요하다.

다이나믹 매핑을 지원하지만 최적의 성능을 위해서 매핑을 최적화 할 필요가 있다.

먼저 conf파일의 output 플러그인을 es로 설정해준다. 인덱스는 dev tools에서 만들어낼 index의 이름을 명시해둔다. 

그러면 ls에서 파이프라인을 통해 파싱된 데이터가 마지막 output단계에서 es의 원하는 index로 흘러들어가게 된다.

```bash
input {
...
filter {
...
output {
  elasticsearch {
    index => "tmdb_5000_movie2"
  }
}	
```

ls를 실행하기 전에 해야할 일이 있다.

es의 index를 생성하고 원하는 형태로 매핑해야한다. 

dev tools에서 실행한다.

```bash
PUT tmdb_5000_movie2
{
  "mappings": {
    "properties": {
      "budget": { "type": "double" },
      "popularity" : { "type": "double" },
      "vote_average" : { "type": "double" },
      "vote_count" : { "type": "double" },
      "id" : { "type": "long" },
      "revenue" : { "type": "long" },
      "runtime" : { "type": "long" },
      "genres" : { "type": "keyword" },
      "original_language" : { "type": "keyword" },
      "status" : { "type": "keyword" },
      "homepage" : { "type": "text" },
      "original_title" : { "type": "text" },
      "overview" : { "type": "text" },
      "tagline" : { "type": "text" },
      "title" : { "type": "text" },
      "release_date" : { "type": "date", "format" : "iso8601" }
    }
  }
}
```

##### 템플릿을 적용하여 로그스태시 데이터 저장

템플릿을 적용하면 설정이 동일한 복수의 인덱스를 만들 떄 유리하다. 

-> 실시간 데이터 받을 때 주로 많이 사용한다. 

```bash
PUT _index_template/tmdb
{
  "index_patterns":"tmdb_5000_movie*",
  "priority":1,
  "template":{
    "mappings":{
      "properties":{
        "budget": { "type": "double" },
        "popularity" : { "type": "double" },
        "vote_average" : { "type": "double" },
        "vote_count" : { "type": "double" },
        "id" : { "type": "long" },
        "revenue" : { "type": "long" },
        "runtime" : { "type": "long" },
        "genres" : { "type": "keyword" },
        "original_language" : { "type": "keyword" },
        "status" : { "type": "keyword" },
        "homepage" : { "type": "text" },
        "original_title" : { "type": "text" },
        "overview" : { "type": "text" },
        "tagline" : { "type": "text" },
        "title" : { "type": "text" },
        "release_date" : { "type": "date", "format" : "iso8601" }
      }
    }
  }
}

```

es의 index template를 만들어 준 후 ls의 파이프라인 출력 설정만 변경해주면 된다.

```bash
input {
...
filter {
...
output {
  elasticsearch {
    index => "tmdb_5000_movie3"
  }
}	
```

